Metadata-Version: 2.4
Name: sima-like-agent
Version: 0.1.0
Summary: A modular AI agent that learns to play video games through self-improvement, inspired by Google's SIMA 2
Author: SIMA2 Mini Team
License: MIT
Project-URL: Homepage, https://github.com/your-org/sima-like-agent
Project-URL: Repository, https://github.com/your-org/sima-like-agent
Project-URL: Issues, https://github.com/your-org/sima-like-agent/issues
Keywords: ai,reinforcement-learning,gaming,sima,self-improvement
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.24.0
Requires-Dist: torch>=2.0.0
Requires-Dist: dataclasses-json>=0.6.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: loguru>=0.7.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.5.0; extra == "dev"
Dynamic: license-file

# SIMA-Like Agent

A modular AI agent that learns to play video games through self-improvement, inspired by Google's SIMA 2.

## Overview

This project implements the skeleton of a research application where an AI agent learns to play video games through a self-improvement cycle similar to Google's SIMA 2. The system includes:

- **Task Setter**: Proposes tasks with estimated rewards
- **Agent**: Executes tasks in game environments  
- **Reward Model**: Evaluates episode performance
- **Self-Generated Experience**: Stores and manages episode data
- **Self-Improvement Loop**: Orchestrates the learning cycle

This virtuous cycle of iterative improvement paves the way for a future where agents can learn and grow with minimal human intervention, becoming open-ended learners in embodied AI.

## Architecture

```
┌─────────────┐    ┌──────────────┐    ┌─────────────┐
│ Task Setter │────│    Agent     │────│ Game Env    │
└─────────────┘    └──────────────┘    └─────────────┘
       │                   │
       │            ┌──────▼──────┐
       │            │  Episodes   │
       │            └──────┬──────┘
       │                   │
       ▼            ┌──────▼──────┐
┌─────────────┐     │ Self-Gen.   │     ┌─────────────┐
│Reward Model │◄────│ Experience  │────►│   Storage   │
└─────────────┘     └─────────────┘     └─────────────┘
```

## Installation

```bash
pip install -e .
```

For development:
```bash
pip install -e ".[dev]"
```

## Quick Start

### Train the agent
```bash
python -m src.main --mode train --generations 10 --episodes-per-gen 5
```

### Run a single episode
```bash
python -m src.main --mode play-once --task-id "reach_goal"
```

### Inspect stored experience
```bash
python -m src.main --mode inspect-buffer
```

## Project Structure

```
sima_like_agent/
├── pyproject.toml
├── README.md
├── src/
│   ├── main.py                    # Entry point and CLI
│   ├── config/
│   │   └── config.py             # Configuration classes
│   ├── env/
│   │   ├── base_env.py           # Abstract game environment
│   │   ├── dummy_env.py          # Simple test environment
│   │   ├── io_controller.py      # Game I/O interfaces
│   │   └── vision.py             # Observation encoding
│   ├── agent/
│   │   ├── policy.py             # Policy implementations
│   │   └── agent.py              # Main agent orchestrator
│   ├── tasks/
│   │   ├── task_schema.py        # Task data structures
│   │   └── task_setter.py        # Task generation logic
│   ├── reward/
│   │   └── reward_model.py       # Episode scoring
│   ├── experience/
│   │   ├── types.py              # Core data types
│   │   ├── buffer.py             # In-memory experience store
│   │   └── storage.py            # Persistent experience store
│   ├── training/
│   │   └── self_improvement_loop.py  # Main training loop
│   └── utils/
│       ├── logging_utils.py      # Structured logging
│       └── seed.py               # Random seed management
└── tests/
    ├── test_experience.py        # Experience system tests
    └── test_agent_interfaces.py  # Agent integration tests
```

## Key Components

### Environment Interface
The `GameEnv` abstract base class provides a clean interface for any video game. Currently includes a `DummyGameEnv` for testing.

### Experience System
Episodes are stored both in-memory (`ReplayBuffer`) and persistently (`storage.py`) as the "Self-Generated Experience" that drives learning.

### Task Generation
The `TaskSetter` proposes new tasks based on previous performance, with hooks for LLM-based task generation.

### Reward Learning
The `RewardModel` scores episodes, with clear interfaces for plugging in learned reward functions or LLM-based evaluation.

## Development

### Running Tests
```bash
pytest tests/
```

### Code Quality
```bash
black src/ tests/
ruff src/ tests/
mypy src/
```

## TODOs for Production Use

1. **Environment Integration**: Replace `DummyGameEnv` with real game wrappers
2. **Vision Models**: Plug in CNN/transformer backbones in `vision.py`
3. **RL Algorithms**: Implement proper policy gradient/Q-learning in `policy.py`
4. **Reward Learning**: Train neural reward models or integrate LLM evaluation
5. **Task Generation**: Add LLM-based creative task generation
6. **Scalability**: Add distributed training and experience storage

## License

MIT License - see LICENSE file for details.

